{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense,\n                                     Embedding, Bidirectional, LSTM, Attention, Flatten,\n                                     Input, Concatenate)\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:29:26.968785Z","iopub.execute_input":"2025-02-12T16:29:26.968998Z","iopub.status.idle":"2025-02-12T16:29:41.607211Z","shell.execute_reply.started":"2025-02-12T16:29:26.968978Z","shell.execute_reply":"2025-02-12T16:29:41.606498Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Define dataset paths\nDATASET_PATH = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"\nIMG_SIZE = 224\n\n# Function to load images and labels\ndef load_images_from_folder(folder):\n    images = []\n    labels = []\n    file_paths = []\n    \n    for category in [\"NORMAL\", \"PNEUMONIA\"]:\n        path = os.path.join(folder, category)\n        label = 0 if category == \"NORMAL\" else 1  # Binary labels: 0 for normal, 1 for pneumonia\n        \n        for img_name in os.listdir(path):\n            img_path = os.path.join(path, img_name)\n            img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE), color_mode=\"grayscale\")\n            img = img_to_array(img) / 255.0  # Normalize pixels\n            images.append(img)\n            labels.append(label)\n            file_paths.append(img_path)\n    \n    return np.array(images), np.array(labels), file_paths\n\n# Load train, validation, and test sets\nX_train_img, y_train, train_paths = load_images_from_folder(os.path.join(DATASET_PATH, \"train\"))\nX_val_img, y_val, val_paths = load_images_from_folder(os.path.join(DATASET_PATH, \"val\"))\nX_test_img, y_test, test_paths = load_images_from_folder(os.path.join(DATASET_PATH, \"test\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:29:56.138434Z","iopub.execute_input":"2025-02-12T16:29:56.138740Z","iopub.status.idle":"2025-02-12T16:31:01.098798Z","shell.execute_reply.started":"2025-02-12T16:29:56.138695Z","shell.execute_reply":"2025-02-12T16:31:01.098100Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Function to generate synthetic text reports based on labels\ndef generate_synthetic_report(label):\n    normal_reports = [\n        \"The lungs appear clear with no significant abnormalities.\",\n        \"No evidence of infection, tumor, or pleural effusion.\",\n        \"Lung fields are normal with no signs of consolidation.\"\n    ]\n    \n    pneumonia_reports = [\n        \"Chest X-ray shows increased opacity in the right lung suggestive of pneumonia.\",\n        \"Findings consistent with bacterial pneumonia, with patchy infiltrates.\",\n        \"Diffuse consolidation and bronchial thickening noted, indicating infection.\"\n    ]\n    \n    return random.choice(normal_reports if label == 0 else pneumonia_reports)\n\n# Create synthetic text dataset\ntrain_reports = [generate_synthetic_report(label) for label in y_train]\nval_reports = [generate_synthetic_report(label) for label in y_val]\ntest_reports = [generate_synthetic_report(label) for label in y_test]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:31:16.652972Z","iopub.execute_input":"2025-02-12T16:31:16.653251Z","iopub.status.idle":"2025-02-12T16:31:16.662311Z","shell.execute_reply.started":"2025-02-12T16:31:16.653229Z","shell.execute_reply":"2025-02-12T16:31:16.661210Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"MAX_VOCAB = 5000\nMAX_LENGTH = 50  # Shorter length since reports are small\n\n# Tokenizer setup\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(train_reports)\n\n# Convert text to sequences & pad\nX_train_txt = pad_sequences(tokenizer.texts_to_sequences(train_reports), maxlen=MAX_LENGTH)\nX_val_txt = pad_sequences(tokenizer.texts_to_sequences(val_reports), maxlen=MAX_LENGTH)\nX_test_txt = pad_sequences(tokenizer.texts_to_sequences(test_reports), maxlen=MAX_LENGTH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:31:19.420690Z","iopub.execute_input":"2025-02-12T16:31:19.421004Z","iopub.status.idle":"2025-02-12T16:31:19.541998Z","shell.execute_reply.started":"2025-02-12T16:31:19.420981Z","shell.execute_reply":"2025-02-12T16:31:19.541406Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Image Model (CNN)\nimage_input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\nx = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(image_input)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation=\"relu\")(x)\nimage_output = Model(image_input, x)\n\n# Text Model (BiLSTM + Attention)\ntext_input = Input(shape=(MAX_LENGTH,))\nembedding_layer = Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LENGTH)(text_input)\nlstm_out = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n\n# Custom Attention Layer\nattention_layer = Attention()([lstm_out, lstm_out])\nflat_layer = Flatten()(attention_layer)\ntext_output = Dense(128, activation=\"relu\")(flat_layer)\ntext_model = Model(text_input, text_output)\n\n# Fusion Layer\ncombined = Concatenate()([image_output.output, text_model.output])\nfusion_output = Dense(64, activation=\"relu\")(combined)\nfinal_output = Dense(1, activation=\"sigmoid\")(fusion_output)\n\n# Compile Model\nmodel = Model(inputs=[image_input, text_input], outputs=final_output)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:31:22.198138Z","iopub.execute_input":"2025-02-12T16:31:22.198423Z","iopub.status.idle":"2025-02-12T16:31:25.059978Z","shell.execute_reply.started":"2025-02-12T16:31:22.198401Z","shell.execute_reply":"2025-02-12T16:31:25.059002Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"history = model.fit(\n    [X_train_img, X_train_txt], y_train,\n    validation_data=([X_val_img, X_val_txt], y_val),\n    batch_size=32,\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:31:29.893748Z","iopub.execute_input":"2025-02-12T16:31:29.894049Z","iopub.status.idle":"2025-02-12T16:32:54.271479Z","shell.execute_reply.started":"2025-02-12T16:31:29.894026Z","shell.execute_reply":"2025-02-12T16:32:54.270799Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.8922 - loss: 0.2439 - val_accuracy: 1.0000 - val_loss: 9.9889e-20\nEpoch 2/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.7276e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 3/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.8321e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 4/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.7272e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 5/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.8805e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 6/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.8934e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 7/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.8383e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 8/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.7751e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 9/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.8765e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\nEpoch 10/10\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.8571e-20 - val_accuracy: 1.0000 - val_loss: 9.9887e-20\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_acc = model.evaluate([X_test_img, X_test_txt], y_test)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:32:57.434273Z","iopub.execute_input":"2025-02-12T16:32:57.434612Z","iopub.status.idle":"2025-02-12T16:32:58.191248Z","shell.execute_reply.started":"2025-02-12T16:32:57.434582Z","shell.execute_reply":"2025-02-12T16:32:58.190392Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.3457e-19\nTest Accuracy: 1.0000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def predict_diagnosis(image_path, text_report):\n    # Preprocess image\n    img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE), color_mode=\"grayscale\")\n    img = img_to_array(img) / 255.0\n    img = np.expand_dims(img, axis=0)\n\n    # Preprocess text\n    text_seq = pad_sequences(tokenizer.texts_to_sequences([text_report]), maxlen=MAX_LENGTH)\n\n    # Predict\n    prediction = model.predict([img, text_seq])[0][0]\n    return \"Pneumonia\" if prediction > 0.5 else \"Normal\"\n\n# Test with new data\ntest_image_path = test_paths[0]  # Example test image\ntest_text_report = generate_synthetic_report(1)  # Generate a pneumonia report\nprint(\"Diagnosis:\", predict_diagnosis(test_image_path, test_text_report))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:33:01.060923Z","iopub.execute_input":"2025-02-12T16:33:01.061205Z","iopub.status.idle":"2025-02-12T16:33:01.420816Z","shell.execute_reply.started":"2025-02-12T16:33:01.061184Z","shell.execute_reply":"2025-02-12T16:33:01.419968Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\nDiagnosis: Pneumonia\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}